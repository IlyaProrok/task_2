{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZ6fAqSlvH+6Wmd0OzfO9j"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D23shHki5_KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install lyricsgenius\n",
        "!pip install -U pip\n",
        "!pip install -U dill\n",
        "!pip install -U nltk==3.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2huXugIXfZNd",
        "colab_type": "code",
        "outputId": "98b288a1-6c6b-45c0-d545-60f4d759052e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import lyricsgenius\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "from nltk import tokenize\n",
        "from nltk.tokenize import LineTokenizer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cULWJubXfe2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genius = lyricsgenius.Genius(\"iihP9u6cVKE79Xtu99OH6rVZlMUzIMeOvIVs8BDQNDeVmZhXJXEaI28E6QOc4BdB\")\n",
        "genius.remove_section_headers = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEuo5G2ZA3mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "artist = genius.search_artist(\"Oxxxymiron\", max_songs=100, sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12TBjtrlcm9z",
        "colab_type": "code",
        "outputId": "efaab7f6-5ab8-490a-8b81-102be10eeb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "artist.save_lyrics(extension='txt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote `Lyrics_Oxxxymiron.txt`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OS5Uhfjc-aH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lyricss = open(\"Lyrics_Oxxxymiron.txt\",\"r\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIUL2shyxM0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in lyricss]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg7JIPQ_5xME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for strokes in tokenized_text:\n",
        "  strokes.append('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBMiayJhxpMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 3\n",
        "train_data3, padded_sents3 = padded_everygram_pipeline(n, tokenized_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fu22xJvxt05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.lm import MLE\n",
        "model = MLE(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iobw1Qrxv4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85ce6629-d17d-43f2-e132-e6be7322e284"
      },
      "source": [
        "model.fit(train_data3, padded_sents3)\n",
        "print(model.vocab)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary with cutoff=1 unk_label='<UNK>' and 11760 items>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEqGq72iyEr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(model, num_words, random_seed=42):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6MivZ-L702l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "69a82e66-219c-4605-b716-c1f5b48a60cc"
      },
      "source": [
        "for i in range(10):\n",
        "    line = generate_sent(model, 10, random_seed=i+10)\n",
        "    if line:\n",
        "      i = 0\n",
        "      while not line[i].isalpha():\n",
        "        i += 1\n",
        "      print(line[i:].capitalize())\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Всегда видят лишь негатив, положив на весы\n",
            "Коллеги твердят:``может хомяка положите туда\n",
            "Abab — рифмовка никуда, ерунда!\n",
            "Бра\n",
            "Школу! сколько было всего, что я хочу сказать\n",
            "И каждый вес мутит, а мой менталитет\n",
            "Бит и бас, это наш год! до тебя\n",
            "Как раньше: лёд всё тоньше\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_t5Dj549T5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7730d944-54a3-4bfb-af0e-4f0845d27624"
      },
      "source": [
        "lk = generate_sent(model, 10, random_seed=14)\n",
        "lk[4].isalpha()"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRbUyHN2yGar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_sent(model, 200, random_seed=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sudyXKtp2m2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "songs = []\n",
        "for line in lyricss:\n",
        "  line = word_tokenize(line)\n",
        "  for word in line:\n",
        "    word.lower()\n",
        "  songs.append(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDxQliORcQG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f60e02d5-4893-4ac8-fb2b-683774de2a4e"
      },
      "source": [
        "songs[690][0].lower()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'добро'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZIh3v2jctvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "songss = []\n",
        "for line in songs:\n",
        "  line = [x.lower() for x in line]\n",
        "  songss.append(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V1i0-VZgtcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "songss_no_nl = songss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czJ7cSRvyJF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for strokes in songss:\n",
        "  strokes.append('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi3negB1g1nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vf0zpjCg9st",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(songss, test_size=0.3, random_state=11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx2dgc-bkliq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ruEXMISY5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLL7TyKUkwWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = []\n",
        "for i in test:\n",
        "  testset.append(list(everygrams(list(pad_both_ends(i, n=2)),max_len=2)))\n",
        "testset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cna4IX7sOoi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.lm import MLE\n",
        "model = MLE(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IygqXK7NmZ7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.lm import Laplace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtiWVXf7meSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = KneserNeyInterpolated(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trwAMBCWjXNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = Laplace(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8EUqRx1X0Bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "train3, vocabul3 = padded_everygram_pipeline(2, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78W_vlFRwLFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ngramlize_sent in train3:\n",
        "    print(list(ngramlize_sent))\n",
        "    print()\n",
        "print('#############')\n",
        "list(vocabul3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYfA1N1eYozS",
        "colab_type": "code",
        "outputId": "aefbdea9-33a5-45a5-f74c-ec2f466331d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(model2.vocab)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21-SFVgDXXha",
        "colab_type": "code",
        "outputId": "eae4a680-e5e2-4bc2-8dbd-dfe48cf9c523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model2.fit(train3, vocabul3)\n",
        "print(model2.vocab)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary with cutoff=1 unk_label='<UNK>' and 8986 items>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpU5Gq1BjfuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.fit(train3, vocabul3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPW009yOhZ18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ef2adff-8a74-4138-fead-a35675e94b97"
      },
      "source": [
        "len(model2.vocab)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVfWHEcTmi76",
        "colab_type": "code",
        "outputId": "a6e6d429-162a-45a9-acbe-544717448950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model2.fit(train, vocabul)\n",
        "print(model2.vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary with cutoff=1 unk_label='<UNK>' and 8376 items>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3G2wzSiZTKv",
        "colab_type": "code",
        "outputId": "278d0def-199a-41b9-efe8-cecdc2f2d43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model2.counts)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<NgramCounter with 2 ngram orders and 77026 ngrams>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwufOVU3ZgbB",
        "colab_type": "code",
        "outputId": "110e61f5-8806-4daa-ae5e-2241f1cc9f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model3.generate(20,random_seed = 41))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['более-менее', 'всё', 'наскоро', ',', 'как', 'кляп', ',', 'как', 'кляп', ',', 'как', 'кляп', ',', 'как', 'кляп', ',', 'как', 'кляп', ',', 'как']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjnqdUwLZqxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(model, num_words, random_seed=42):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed):\n",
        "        if token != '</s>':\n",
        "            content.append(token)\n",
        "    return detokenize(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPyu5F8wZr_5",
        "colab_type": "code",
        "outputId": "632ef570-a299-448b-8d25-e6490d5c915d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(generate_sent(model, 200, random_seed = 41))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<UNK>, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав, едва заслышав ,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJzRlla-q_KI",
        "colab_type": "code",
        "outputId": "7346ee12-6c66-41f6-c139-4cde5c3d9bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "artist = genius.search_artist(\"Oxxxymiron\", max_songs=3, sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching for songs by Oxxxymiron...\n",
            "\n",
            "Song 1: \"16 Bars Acapella\"\n",
            "Song 2: \"Afterparty (Demo)\"\n",
            "Song 3: \"AI Ogon\"\n",
            "\n",
            "Reached user-specified song limit (3).\n",
            "Done. Found 3 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoUUcQwwLzMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09mRjwM8OGkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwdmHBuRqnf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(genius.search_song(\"16 Bars Acapella\", \"Oxxxymiron\").lyrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3DKLI1uBXyI",
        "colab_type": "code",
        "outputId": "755fef7d-b543-4f69-fa61-e272b15f5c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(artist.songs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Alexander All Alone', 'Andy Shauf'), ('All the Same', 'Andy Shauf'), ('Angela', 'Andy Shauf'), ('To You', 'Andy Shauf')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}