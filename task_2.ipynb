{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semifinal.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D23shHki5_KR",
        "colab": {}
      },
      "source": [
        "# installing necessery packages\n",
        "!pip install lyricsgenius\n",
        "!pip install -U pip\n",
        "!pip install -U dill\n",
        "!pip install nltk==3.5b1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2huXugIXfZNd",
        "outputId": "dd274f80-938a-4ad9-8bbf-022119ed6a04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# some imports\n",
        "import lyricsgenius\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "from nltk import tokenize\n",
        "from nltk.tokenize import LineTokenizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm import Laplace\n",
        "from nltk.lm import KneserNeyInterpolated\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "import random\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.lm import Vocabulary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESXJAnB4RZm9",
        "colab_type": "text"
      },
      "source": [
        "# **Foreword**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fevD9EW7hj-",
        "colab_type": "text"
      },
      "source": [
        "As a first iteration of an exercise I downloaded the lyrics of all the songs of Oxxymiron (88 songs) and built uni- and bigram model training them on the songs. Results were pretty satisfying but I had problems with culculating perplexity of the models. \n",
        "\n",
        "Following your advices I updated nltk to v3.5b1 and the problem with perplexity has gone. \n",
        "\n",
        "I also increased corpus size by adding all the songs of Slava KPSS, Noize MC and FACE (257, 271 and 135 songs, respectively). The final corpus consisted of approximately 40k lines of rap. However, when generating the lyrics with models trained on this corpus I faced anoother problem: computational. The lyrics were generating too slowly (for not MLE models): for example, I left the model generating the whole night (at least 8 hours) and in the morning it only generated **TWO** lines (10 words long each). I'm not even mentioning perplexities, I think it could take ages to compute them.\n",
        "\n",
        "Thus, I decided to decrease the corpus a little bit to compare models and to show that they work, and left 20 songs of each artist in order to maintain style differentiation :) \n",
        "\n",
        "(to download the whole corpora just set the parameter \"max_songs\" in search_artist method to None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3uDdwlvRibb",
        "colab_type": "text"
      },
      "source": [
        "# **Collecting and prepocessing the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cULWJubXfe2e",
        "colab": {}
      },
      "source": [
        "# initializing genius class\n",
        "genius = lyricsgenius.Genius(\"iihP9u6cVKE79Xtu99OH6rVZlMUzIMeOvIVs8BDQNDeVmZhXJXEaI28E6QOc4BdB\")\n",
        "genius.remove_section_headers = True\n",
        "genius.skip_non_songs = False \n",
        "genius.excluded_terms = [\"(Remix)\", \"(Live)\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SEuo5G2ZA3mO",
        "outputId": "3f4b82c4-038e-4566-c6c8-dad0d688f2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "# Collecting Oxxxymiron songs\n",
        "Oxxxymiron = genius.search_artist(\"Oxxxymiron\",max_songs=20, sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching for songs by Oxxxymiron...\n",
            "\n",
            "Song 1: \"16 Bars Acapella\"\n",
            "Song 2: \"Afterparty (Demo)\"\n",
            "Song 3: \"AI Ogon\"\n",
            "Song 4: \"Amplify and simplify (Freestyle)\"\n",
            "Song 5: \"CCTV\"\n",
            "Song 6: \"Darkside\"\n",
            "Song 7: \"Freestyle #1\"\n",
            "Song 8: \"Ganz Promo Tune\"\n",
            "Song 9: \"Hangover\"\n",
            "Song 10: \"HPL\"\n",
            "Song 11: \"IMPERIVM\"\n",
            "Song 12: \"Intro\"\n",
            "Song 13: \"OXXXYMIRON\"\n",
            "Song 14: \"Russky Cockney\"\n",
            "Song 15: \"Shade 45 Freestyle (Идея)\"\n",
            "Song 16: \"Street Freestyle battle\"\n",
            "Song 17: \"Ultima Thule\"\n",
            "Song 18: \"Unreleased Track\"\n",
            "Song 19: \"Unreleased Track 2\"\n",
            "Song 20: \"Unreleased Track 3\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sOblUhlprVW0",
        "outputId": "aea13ccd-573c-4d97-a452-266d8aefbe6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "source": [
        "# Collecting Slava KPSS songs\n",
        "SlavaKPSS = genius.search_artist(\"Слава КПСС\",max_songs=20, sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching for songs by Слава КПСС...\n",
            "\n",
            "Changing artist name to 'Слава КПСС (Slava KPSS)'\n",
            "Song 1: \"0лик (Zero)\"\n",
            "Song 2: \"100 barz (Нахуй всех!)\"\n",
            "Song 3: \"12 мая (12 may)\"\n",
            "Song 4: \"16 проблем (InDaBattle 3 Round 2)\"\n",
            "Song 5: \"18 марта (18th of March)\"\n",
            "Song 6: \"2,5 человека (DSV Battle Round 1)\"\n",
            "Song 7: \"30 новых авто (30 New Cars)\"\n",
            "Song 8: \"30 новых авто (30 new cars) [Alternative version]\"\n",
            "Song 9: \"5500\"\n",
            "Song 10: \"Black Stalin\"\n",
            "Song 11: \"BLUNTCUT\"\n",
            "Song 12: \"Burlit\"\n",
            "Song 13: \"Comeback\"\n",
            "Song 14: \"CUCKOLDINI\"\n",
            "Song 15: \"Donbass\"\n",
            "Song 16: \"FACE DISS (FACEFVCK)\"\n",
            "Song 17: \"Grime Thing\"\n",
            "Song 18: \"KIBERDEMON FREESTULE\"\n",
            "Song 19: \"King Ring (Freestyle)\"\n",
            "Song 20: \"MONEY TALK\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TAWk0mGjzowZ",
        "outputId": "28cd8282-431c-455b-c711-8dd79fe9f976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "source": [
        "# Collecting NoizeMC songs\n",
        "NoizeMC = genius.search_artist(\"Noize MC\", max_songs=20, sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching for songs by Noize MC...\n",
            "\n",
            "Changing artist name to 'Noize MC'\n",
            "Song 1: \"+−0\"\n",
            "Song 2: \"10 суток (Сталинград) (10 days)\"\n",
            "Song 3: \"12 обезьян (Ляпис Трубецкой cover)\"\n",
            "Song 4: \"18:30\"\n",
            "Song 5: \"200+\"\n",
            "Song 6: \"220\"\n",
            "Song 7: \"2 хороших девочки (2 good girls)\"\n",
            "Song 8: \"3П (Правдивая песня пиздобола) (3P (Liar’s true song)\"\n",
            "Song 9: \"3П (Правдивая песня пиздобола) [Фристайл] (3P (Liar’s true song) [Freestyle])\"\n",
            "Song 10: \"5П (Песня похуиста про получение пиздюлей) (5P)\"\n",
            "Song 11: \"Chasing the Horizon\"\n",
            "Song 12: \"Come $ome All (Тоталитарный трэпъ) (Come Some All)\"\n",
            "Song 13: \"Ctrl+Alt+Delete\"\n",
            "Song 14: \"Face a la Mer (Faced the sea)\"\n",
            "Song 15: \"Funk Soul Brother (Фристайл) (Freestyle)\"\n",
            "Song 16: \"Game Over\"\n",
            "Song 17: \"Hard Reboot\"\n",
            "Song 18: \"Heart Shaped Box + Фристайл (Freestyle)\"\n",
            "Song 19: \"I Am the Rain\"\n",
            "Song 20: \"I’ll Be Back (Фристайл) (Freestyle)\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAflIU14738d",
        "outputId": "275b0e68-cdfe-4e10-c64b-b9017c641f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "# Collecting FACE songs\n",
        "FACE = genius.search_artist(\"FACE\",max_songs=20,  sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching for songs by FACE...\n",
            "\n",
            "Song 1: \"162\"\n",
            "Song 2: \"24 на 7\"\n",
            "Song 3: \"All Good\"\n",
            "Song 4: \"APRIL  8\"\n",
            "Song 5: \"Baby\"\n",
            "Song 6: \"Baby Face\"\n",
            "Song 7: \"Blazer\"\n",
            "Song 8: \"Enter The Void\"\n",
            "Song 9: \"Forever Young\"\n",
            "Song 10: \"Holiday\"\n",
            "Song 11: \"Ian Connor\"\n",
            "Song 12: \"I dropped Gucci\"\n",
            "Song 13: \"I Hate Humans (Unreleased)\"\n",
            "Song 14: \"Instagram\"\n",
            "Song 15: \"I Want\"\n",
            "Song 16: \"January\"\n",
            "Song 17: \"Kanji\"\n",
            "Song 18: \"Karamel\"\n",
            "Song 19: \"KILL\"\n",
            "Song 20: \"MASK\"\n",
            "\n",
            "Reached user-specified song limit (20).\n",
            "Done. Found 20 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "12TBjtrlcm9z",
        "outputId": "47fb2613-efb1-407d-ee60-2db75c1e0eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# saving the lyrics of all songs to separate files\n",
        "Oxxxymiron.save_lyrics(extension='txt')\n",
        "SlavaKPSS.save_lyrics(extension='txt')\n",
        "NoizeMC.save_lyrics(extension='txt')\n",
        "FACE.save_lyrics(extension='txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote `Lyrics_Oxxxymiron.txt`\n",
            "Wrote `Lyrics_СлаваКПССSlavaKPSS.txt`\n",
            "Wrote `Lyrics_NoizeMC.txt`\n",
            "Wrote `Lyrics_FACE.txt`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8OS5Uhfjc-aH",
        "colab": {}
      },
      "source": [
        "# opening them back \n",
        "Oxy_lyrics = open(\"Lyrics_Oxxxymiron.txt\",\"r\")\n",
        "Slava_lyrics = open(\"Lyrics_СлаваКПССSlavaKPSS.txt\",\"r\")\n",
        "Noize_lyrics = open(\"Lyrics_NoizeMC.txt\",\"r\")\n",
        "FACE_lyrics = open(\"Lyrics_FACE.txt\",\"r\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIUL2shyxM0W",
        "colab": {}
      },
      "source": [
        "# tokenizing the lyrics, lowering all the words (we will capitalize them back soon :) and leaving all punkt as it is (it will make our generated lyrics\n",
        "# look more natural)\n",
        "# In the end we get list of lists (lines in songs) of tokenized words, \n",
        "# so Oxy_tokenized[0] is not the 1st song of Oxxy but the 1st line of all the downloaded Oxy lyrics \n",
        "Oxy_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in Oxy_lyrics]\n",
        "Slava_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in Slava_lyrics]\n",
        "Noize_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in Noize_lyrics]\n",
        "FACE_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in FACE_lyrics]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JBKgnIp0-qJM",
        "outputId": "58175011-3f25-4084-dcf0-e9c58a96b63e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# checking the length of the corpora (num of lines of rap)\n",
        "print(len(Oxy_tokenized),len(Slava_tokenized),len(Noize_tokenized),len(FACE_tokenized))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1157 1229 1222 765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BILLTGug9WYS",
        "outputId": "589a9953-7e2d-4976-9c7c-a6824c8cb532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# combine all the lyrics into one list\n",
        "all_lyrics = []\n",
        "all_lyrics.extend(Oxy_tokenized)\n",
        "all_lyrics.extend(Slava_tokenized)\n",
        "all_lyrics.extend(Noize_tokenized)\n",
        "all_lyrics.extend(FACE_tokenized)\n",
        "print(len(all_lyrics))\n",
        "print(len(Oxy_tokenized)+len(Slava_tokenized)+len(Noize_tokenized)+len(FACE_tokenized))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4373\n",
            "4373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtkyp9lKLVwh",
        "colab_type": "text"
      },
      "source": [
        "I also had an idea of first of all dividing the lyrics into sentences and leave \\n synmbols as indicators of new line, so the generator could make newline itself. But the artists didnt include full stop marks to their Lyrics, so itis impossible to tokenize sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lg7JIPQ_5xME",
        "colab": {}
      },
      "source": [
        "# Firstly, I was thinking, that adding \\n symbol is a good idea to let the model know, where to start the next line,\n",
        "# but then i neglected the idea\n",
        "# for strokes in tokenized_text:\n",
        "#   strokes.append('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQQW1LmwMQgs",
        "colab_type": "text"
      },
      "source": [
        "Then I defined a function the generate a rap lyrics given model, line size and number of lines. I also included into this function detokenizer and capitalizer to make the lyrics look pretty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aZsBp0KUWdKj",
        "colab": {}
      },
      "source": [
        "# def a function to generate rap text given a model\n",
        "def rap_gen(model, num_lines = 20, num_words_in_line = 20, random_seed = 0):\n",
        "  \"\"\"\n",
        "  The function generates rap lyrics. This is a very creative process, so be aware,\n",
        "  that the number of words in lines and even number of lines may be less than you desired \n",
        "  (it totally depends on the function's inspiration (and random_seed)) :)\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_lines: Max no. of lines to generate.\n",
        "    :param num_words_in_line: Max no. of words in line to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "  detokenize = TreebankWordDetokenizer().detokenize\n",
        "  for i in range(num_lines):\n",
        "    content = []\n",
        "    for token in model.generate(num_words_in_line, random_seed=random_seed+i):\n",
        "      if token == '<s>':\n",
        "        continue\n",
        "      if token == '</s>':\n",
        "        break\n",
        "      content.append(token)\n",
        "    content = detokenize(content)\n",
        "    if bool(content):\n",
        "      i = 0\n",
        "      while not content[i].isalpha():\n",
        "          i += 1\n",
        "          if i > len(content)-1:\n",
        "            break\n",
        "      print(content[i:].capitalize())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NXFpQ9hWSP1f",
        "colab": {}
      },
      "source": [
        "# divide into test and train set. Leave test size not very big to better train the model and faster estimate perplexity. \n",
        "train, test = train_test_split(all_lyrics, test_size=0.2, random_state=11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBGOZmIPRWn9",
        "colab_type": "text"
      },
      "source": [
        "# **Boulding models**\n",
        "I decided to build all in all 9 models: MLE, Laplace smoothing and KneseNey smoothing interpolation based on uni-, bi- and trigrams.\n",
        "\n",
        "After each model there is an example of generated rap.\n",
        "\n",
        "BE AWARE, RUSSIAN CURSE AND SWEAR WORDS ARE NOT CENSORED. 18+ CONTENT. \n",
        "\n",
        "If you are not Okay with it, go back and change the list of artists to, for example, Yurii Loza, Sofia Rotaru or Valeriy Meladze."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K3sANXcx_brs"
      },
      "source": [
        "***Unigram* models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9HwYorYV_dpL",
        "colab": {}
      },
      "source": [
        "model1_MLE = MLE(1)\n",
        "train_data1_1, padded_sents1_1 = padded_everygram_pipeline(1, train)\n",
        "model1_MLE.fit(train_data1_1, padded_sents1_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GQK--1DO_bF1",
        "outputId": "8f88a681-3ff3-4c1d-f8c9-d4fc0dedcb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "rap_gen(model1_MLE, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Каждый о оксибутиратом?! дебила бы среди перевороты нас\n",
            "Бля папки пальцы тлеющий long «``you про.\n",
            "По ноль этим будут бить про о в памяти\n",
            "Я! прожигает check ёбнем 'em у отряд тоталитарный ”\n",
            "Гроб как за и её о бля неуловимой! в\n",
            "Лимонова сотрясается я в с по-твоему обсираешь ,) для\n",
            "It обсуди всем radmir кем когда как иду брат бесплатный\n",
            "От сердце ли кто-то другом — в about более бодрый\n",
            "Хочу парней с хочешь боба ни хочу ты мы funk\n",
            "Face пепла неуловимый как told скоро спасибо куда-то который а\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hbkc7Kam_v-K",
        "colab": {}
      },
      "source": [
        "model1_Lapl = Laplace(1)\n",
        "train_data1_2, padded_sents1_2 = padded_everygram_pipeline(1, train)\n",
        "model1_Lapl.fit(train_data1_2, padded_sents1_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z5dRT2szAC9t",
        "outputId": "5fc5f4cf-070d-4637-828c-431c6324cea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "rap_gen(model1_Lapl, num_lines=10,num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Кодати от палева good! дыр вам сосут поближе не\n",
            "В плачу плавает тебя think бицевском hype бейп протеста cross\n",
            "Полет они чёрных в бычки против от вряд плаву\n",
            "Я' прошу made ядерный (ты пиздуй то ”\n",
            "Длинном контингент золото истиной звать от в нужна! время\n",
            "Мгновенно собой эфире вкладчики с полу отличный ;) есть\n",
            "Take отличный горы you крикни кто-то конечно как в было\n",
            "Песни серию масштабах любимую жить — виски i в в\n",
            "Фьорд пломбы с фристайлить в ныть фрэнд тут наблюдаешь prophets\n",
            "Of по нужна кому-то антихайп скитальца создал любовь либерию более\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6sNVOUUNKClt",
        "colab": {}
      },
      "source": [
        "model1_KNI = KneserNeyInterpolated(1)\n",
        "train_data1_3, padded_sents1_3 = padded_everygram_pipeline(1, train)\n",
        "model1_KNI.fit(train_data1_3, padded_sents1_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uU4YaaKwKVN0",
        "outputId": "0dad1e3d-645c-46c3-a6f3-7e3f2383d915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "rap_gen(model1_KNI, num_lines=10,num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Меж поздравляю получал блока asbestos какого-то дерьма смешно представляю очках\n",
            "Давидофф почетное похожий строки виллу герасима более-менее выше рай безумно\n",
            "Автэ приходят подписывал хайпить демо-тейп грязь рай пойду ебет похотливый\n",
            "Честная b раскисли брэшвилл экс-ан-прованс bredrin тнт пот счастью ”\n",
            "Имею мечты кости лечь конч позер давать пластоу and ебанись\n",
            "Наскучило слушать часам домосед самом проанализировал покрываюсь алкоголя die качать\n",
            "Взгляни покрываюсь запомните возраста мо мокрая метро любовью двигаем грузин\n",
            "Посвящаю серых народ надевал клоны яркие домой больного дальнейшей дай-дай\n",
            "Убьем пою самоубийцы убил дадут плачут убитый телек огромный ваш\n",
            "Бьёшь предельно пластоу метастазами выбор скажи слюни надеюсь мэйна глупо\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drKFNlQNSabX",
        "colab_type": "text"
      },
      "source": [
        "Model based on unigrams generate a list of unconnected words, and it can not be called \"nornal lyrics for rap song\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7lhEfp-7EXOx"
      },
      "source": [
        "**Everygram models (until *bigram*)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Udr5R9fSLO3u",
        "colab": {}
      },
      "source": [
        "model2_MLE = MLE(2)\n",
        "train_data2_1, padded_sents2_1 = padded_everygram_pipeline(2, train)\n",
        "model2_MLE.fit(train_data2_1, padded_sents2_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Fu22xJvxt05",
        "outputId": "07846596-1232-4ef8-aa8f-9687c5731691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "rap_gen(model2_MLE, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Все под оксибутиратом\n",
            "Приводит иногда я гнал\n",
            "Лет десяток!\n",
            "Я, сын, я - это пидоролитет\n",
            "Me?\n",
            "Достоин даже цикад\n",
            "На твой половой зрелости аттестат?\n",
            "У нас не такой, посмотрите-ка, что опопсел?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6iobw1Qrxv4T",
        "colab": {}
      },
      "source": [
        "model2_Lapl = Laplace(2)\n",
        "train_data2_2, padded_sents2_2 = padded_everygram_pipeline(2, train)\n",
        "model2_Lapl.fit(train_data2_2, padded_sents2_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NKySLgRKLBoR",
        "outputId": "2a8b2b17-59bd-4f2d-9ce0-bdf366a3959f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "rap_gen(model2_Lapl, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Для предупреждения мы двигаем всех, если ты пёрнул в\n",
            "Потому что у\n",
            "Этой бригады мои бродяги, but your lens\n",
            "Берегись тут мафия носит скорее погоны мвд\n",
            "И страх, ждать шестьдесят дней вот более-менее всё ещё\n",
            "По крайней мере\n",
            "Неизбежен: « джианни мора »\n",
            "У нас не твой друг и умереть молодым\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJRYwAhYdTLO",
        "colab": {}
      },
      "source": [
        "model2_KNI = KneserNeyInterpolated(2)\n",
        "train_data2_3, padded_sents2_3 = padded_everygram_pipeline(2, train)\n",
        "model2_KNI.fit(train_data2_3, padded_sents2_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hiOAqhZFLEBl",
        "outputId": "41bce838-3214-4f47-ea90-7eb9cf94925f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "rap_gen(model2_KNI, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Медсестра\n",
            "Давать мне от того, давай, да? )\n",
            "Авторы задрочены\n",
            "Честная, так . я - это пидоролитет\n",
            "Иметь со мной\n",
            "Насколько я читаю какие-то странные цацы\n",
            "Взгляд – обожаю\n",
            "Посаженых мойрой, не изобретёнными\n",
            "Убьем эту тупизну рогами пробьет\n",
            "Бьют тебя нихуя\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGcAjmKyTH5h",
        "colab_type": "text"
      },
      "source": [
        "Model based on bigrams generate quite good texts. Manually corrected, generated text can even be used as lyrics to some rap song (yes, I'm not a rap expert)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-VGqVckcLHp7"
      },
      "source": [
        "**Everygram models (until *trigram*)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bz_OfUbhJQDg",
        "colab": {}
      },
      "source": [
        "model3_MLE = MLE(3)\n",
        "train_data3_1, padded_sents3_1 = padded_everygram_pipeline(3, train)\n",
        "model3_MLE.fit(train_data3_1, padded_sents3_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VleANnbaLgVK",
        "outputId": "2da9ca91-c005-402e-8065-e2d5c9d4a111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "rap_gen(model3_MLE, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Money, money, blud . gimme some money\n",
            "Это big up\n",
            "Каждую минуту и секунду, каждый день\n",
            "Больше четверти века набекрень голова\n",
            "Коню за продакшн, зов кандалакши\n",
            "Только польщён\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DkL8a8gyLjci",
        "colab": {}
      },
      "source": [
        "model3_Lapl = Laplace(3)\n",
        "train_data3_2, padded_sents3_2 = padded_everygram_pipeline(3, train)\n",
        "model3_Lapl.fit(train_data3_2, padded_sents3_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sX8v9oA0Lwjo",
        "outputId": "ca65f25a-c491-48ef-d574-e197fa64dab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "rap_gen(model3_Lapl, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Бык, но вздрогнул с немцовских пуль\n",
            "Крикни « ауе », потом второй, и\n",
            "Эта наколка\n",
            "Download mixtape\n",
            "Вырви и выброси . серотонин в минусе\n",
            "Мной сука цвета, будто я герой сартра\n",
            "Трачу свои деньги — и с наганом\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wimJziDoLxaI",
        "colab": {}
      },
      "source": [
        "model3_KNI = KneserNeyInterpolated(3)\n",
        "train_data3_3, padded_sents3_3 = padded_everygram_pipeline(3, train)\n",
        "model3_KNI.fit(train_data3_3, padded_sents3_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z2htw825L3ff",
        "outputId": "22ea9b30-2a96-4ddd-dcec-92a56d96d03d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "rap_gen(model3_KNI, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Медсестра\n",
            "Давать мне, сука, мне в директ\n",
            "Авторы задрочены\n",
            "Честная, как в спортлото\n",
            "Иметь со словом\n",
            "Насколько я старый . стал троцкистом\n",
            "Взгляд – это капец экстаз\n",
            "Посаженых мойрой, следите\n",
            "Убьем эту падлу? )\n",
            "Бьют тебя, сука, что хотел\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gzyk9wxriHNw"
      },
      "source": [
        "Model based on bigrams mostly generate copies of lines of particular songs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMXM060cFCi",
        "colab_type": "text"
      },
      "source": [
        "# **Model evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vVREtGk5iuWH"
      },
      "source": [
        "Can you also give some advise on a model evaluation with perplexity. Thing I did below, unfortunately, do not give desired result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DEHuvi1Ef401",
        "colab": {}
      },
      "source": [
        "test_data1,_ = padded_everygram_pipeline(1, test)\n",
        "test_data2,_ = padded_everygram_pipeline(2, test)\n",
        "test_data3,_ = padded_everygram_pipeline(3, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i0E6oR-pWLdU",
        "colab": {}
      },
      "source": [
        "test_gen1 = []\n",
        "test_gen2 = []\n",
        "test_gen3 = []\n",
        "for line in test_data1:\n",
        "  test_gen1.extend(line)\n",
        "for line in test_data2:\n",
        "  test_gen2.extend(line)\n",
        "for line in test_data3:\n",
        "  test_gen3.extend(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B1OCTA6cgFFN",
        "outputId": "b7f1a541-dbca-4c51-b284-fa97475b230c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for unigram MLE model is: {}'.format(model1_MLE.perplexity(test_gen1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for unigram MLE model is: inf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ak-VJeaBWj5H",
        "outputId": "92b74e5a-ad43-4d09-a201-88d69ee902b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for unigram Laplace model is: {}'.format(model1_Lapl.perplexity(test_gen1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for unigram Laplace model is: 1454.318239940892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M6M8OtwGWtuA",
        "outputId": "d7cf7727-c614-4cd1-9e65-926c20f1d032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for unigram KneserNeyInterpolated model is: {}'.format(model1_KNI.perplexity(test_gen1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for unigram KneserNeyInterpolated model is: 7222.999999998707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_9C-dc1gW2lx",
        "outputId": "eefd1a1e-6112-4f01-a8a3-4222b5e3dedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for bigram MLE model is: {}'.format(model2_MLE.perplexity(test_gen2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for bigram MLE model is: inf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ads7J__gW5sw",
        "outputId": "fd0b6214-cbf5-4c09-e5cc-0034e620ccda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for bigram Laplace model is: {}'.format(model2_Lapl.perplexity(test_gen2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for bigram Laplace model is: 1186.4936058181775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bLeY-uBW9it",
        "outputId": "3c3d507a-bf65-48d9-bfcd-eeb7e7b01ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for bigram KneserNeyInterpolated model is: {}'.format(model2_KNI.perplexity(test_gen2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for bigram KneserNeyInterpolated model is: 2820.7160107988434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-M7lyutpXAw7",
        "outputId": "078b0b11-914c-46b9-885c-597882c3c83f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for trigram MLE model is: {}'.format(model3_MLE.perplexity(test_gen3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for trigram MLE model is: inf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EwDCH3RMXDzc",
        "outputId": "64b86419-26e0-4a6c-c4ea-a04388ddd854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for trigram Laplace model is: {}'.format(model3_Lapl.perplexity(test_gen3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for trigram Laplace model is: 795.3070857094062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "13n0e6j0XGrh",
        "outputId": "0a2639e8-1265-44dc-e0e3-f07ea9905ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for trigram KneserNeyInterpolated model is: {}'.format(model3_KNI.perplexity(test_gen3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for trigram KneserNeyInterpolated model is: 1115.0942101808953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE-z6sQXnFMr",
        "colab_type": "text"
      },
      "source": [
        "**Comment on n-gram models.**\n",
        "\n",
        "According to perplexity, trigram Laplace model is better than any other. But still, perplexity is quite high (at least comparing with numbers from Dan Jurafsky book). \n",
        "I find at least two reasons for that: \n",
        "\n",
        "1) The training sample is too small (computational boundaries)\n",
        "\n",
        "2) Russian rap is not very suitable for n-gram model: I believe, that in russian rap lyrics there are a lot of unique word collocations, which you can not meet in real russian language or in any other rap song. That is why in generated lyrics there are a lot of direct citations from songs: there are no other possible variants to make such a phrase. \n",
        "\n",
        "In order to somehow overcome the second obstacle I decided to experiment with character by character generator (see section beloow)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtAXwHIN6S0T",
        "colab_type": "text"
      },
      "source": [
        "# **Experiments with RNN**\n",
        "\n",
        "> As an experiment I wanted to play with a simple RNN. I found tutorial on implementing RNN for text generation task from Tensorflow ([link](https://www.tensorflow.org/tutorials/text/text_generation)). It was about generating text character by character, and I was interested in how it's gonna was for rap lyrics generation task. Most lines of code are directly borrowed from there with just little changes. Below you can see results of an experiment. Since the RNN generated results much faster, I was able to experiment with corpora of all songs of 4 rappers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuCXTsxvKTpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqfgU90s6btT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download lyrics of all songs of Oxxxymiron, Slava KPSS, Noize MC and FACE. \n",
        "Oxy_lyrics2 = open('Lyrics_Oxxxymiron.txt','rb').read().decode(encoding='utf-8')\n",
        "Slava_lyrics2 = open(\"Lyrics_СлаваКПССSlavaKPSS.txt\",'rb').read().decode(encoding='utf-8')\n",
        "Noize_lyrics2 = open(\"Lyrics_NoizeMC.txt\",'rb').read().decode(encoding='utf-8')\n",
        "FACE_lyrics2 = open(\"Lyrics_FACE.txt\",'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TOL8tw27S7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "effdf792-e67e-4dfd-90bd-ee9f1d26b49e"
      },
      "source": [
        "# concatenate to make the final corpus\n",
        "# check the length of corpora\n",
        "text = Oxy_lyrics2 + '\\n' + Slava_lyrics2 + '\\n' + Noize_lyrics2 + '\\n' + FACE_lyrics2\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1453063 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMPcn2257yR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6f33f4a-7fa7-43c5-df09-03856ee57c34"
      },
      "source": [
        "# Let's look at the si`e of vocabulary\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "191 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGjko2Wy712l",
        "colab_type": "text"
      },
      "source": [
        "Why so many symbols? Let's take a look at the exact symbols."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6rLjs5e8HZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "df74d2e6-ff9a-40f2-de28-bb554f23f23d"
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\t', '\\n', ' ', '!', '\"', '#', '$', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '~', '\\xa0', '«', '»', 'À', 'É', '×', 'à', 'á', 'ç', 'è', 'é', 'ê', 'ë', 'û', '́', 'Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', 'є', 'і', 'ї', 'ғ', 'Қ', 'қ', 'ң', 'ұ', '\\u2005', '\\u200a', '\\u200e', '–', '—', '‘', '’', '“', '”', '„', '…', '\\u205f', '⍰']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOoBW8lL8LE2",
        "colab_type": "text"
      },
      "source": [
        "What are those '\\u2005', '\\u200a', et? After quick check I found out that these are just spaces decoded incorrectly.\n",
        "\n",
        "Let's quickly turn them back to spaces. \n",
        "\n",
        "Also there are symbols from Latin and Kazakh languages, since there are lines in French, Spanish, English and Kazakh in some songs in corpora. I decided leave them there: the more languages, the more interesting! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWimAtkD8Iiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_to_replace = ['\\xa0','\\u2005','\\u200a','\\u200e','\\u205f','⍰']\n",
        "for char in char_to_replace:\n",
        "  text = text.replace(char,' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OitvHwyoJ_qR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recreate the vocabulary\n",
        "vocab = []\n",
        "vocab = sorted(set(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU2mbJjRKKGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0hGaDErKLQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 50\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vQ94VirPP6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ9fUi5mPQZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TZyzq9JPU5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhJYtB-hPXAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(512),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhqM8L-bPaNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DQWtbUCPbRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CyxSFaNT-JG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeMX2RV2Qwpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CSASisIPpc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37761414-fc86-4282-8a34-cfc7f18c200b"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 2.7855\n",
            "Epoch 2/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.2855\n",
            "Epoch 3/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.0656\n",
            "Epoch 4/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.9119\n",
            "Epoch 5/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 1.7918\n",
            "Epoch 6/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.6874\n",
            "Epoch 7/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 1.5901\n",
            "Epoch 8/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.5019\n",
            "Epoch 9/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.4211\n",
            "Epoch 10/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.3507\n",
            "Epoch 11/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 1.2910\n",
            "Epoch 12/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 1.2408\n",
            "Epoch 13/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 1.2004\n",
            "Epoch 14/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 1.1649\n",
            "Epoch 15/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.1397\n",
            "Epoch 16/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.1178\n",
            "Epoch 17/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 1.1000\n",
            "Epoch 18/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0831\n",
            "Epoch 19/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0705\n",
            "Epoch 20/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0609\n",
            "Epoch 21/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0501\n",
            "Epoch 22/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0416\n",
            "Epoch 23/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0340\n",
            "Epoch 24/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0281\n",
            "Epoch 25/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0205\n",
            "Epoch 26/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0160\n",
            "Epoch 27/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0117\n",
            "Epoch 28/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0070\n",
            "Epoch 29/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.0035\n",
            "Epoch 30/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9983\n",
            "Epoch 31/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9947\n",
            "Epoch 32/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9903\n",
            "Epoch 33/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9892\n",
            "Epoch 34/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9862\n",
            "Epoch 35/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9820\n",
            "Epoch 36/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9784\n",
            "Epoch 37/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9784\n",
            "Epoch 38/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9756\n",
            "Epoch 39/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9717\n",
            "Epoch 40/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9706\n",
            "Epoch 41/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 0.9684\n",
            "Epoch 42/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9658\n",
            "Epoch 43/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9633\n",
            "Epoch 44/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9604\n",
            "Epoch 45/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9595\n",
            "Epoch 46/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9574\n",
            "Epoch 47/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9553\n",
            "Epoch 48/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9524\n",
            "Epoch 49/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9515\n",
            "Epoch 50/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9503\n",
            "Epoch 51/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9481\n",
            "Epoch 52/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9462\n",
            "Epoch 53/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9435\n",
            "Epoch 54/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9429\n",
            "Epoch 55/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9410\n",
            "Epoch 56/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9397\n",
            "Epoch 57/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9384\n",
            "Epoch 58/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9374\n",
            "Epoch 59/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9374\n",
            "Epoch 60/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9330\n",
            "Epoch 61/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9311\n",
            "Epoch 62/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9317\n",
            "Epoch 63/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9290\n",
            "Epoch 64/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9295\n",
            "Epoch 65/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9267\n",
            "Epoch 66/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9271\n",
            "Epoch 67/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9235\n",
            "Epoch 68/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9213\n",
            "Epoch 69/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9221\n",
            "Epoch 70/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9206\n",
            "Epoch 71/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9173\n",
            "Epoch 72/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9179\n",
            "Epoch 73/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9170\n",
            "Epoch 74/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9170\n",
            "Epoch 75/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 0.9149\n",
            "Epoch 76/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 0.9133\n",
            "Epoch 77/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9104\n",
            "Epoch 78/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9099\n",
            "Epoch 79/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9094\n",
            "Epoch 80/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9072\n",
            "Epoch 81/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9077\n",
            "Epoch 82/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9062\n",
            "Epoch 83/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9045\n",
            "Epoch 84/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9033\n",
            "Epoch 85/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 0.9031\n",
            "Epoch 86/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9022\n",
            "Epoch 87/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8997\n",
            "Epoch 88/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8989\n",
            "Epoch 89/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.9007\n",
            "Epoch 90/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8969\n",
            "Epoch 91/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8955\n",
            "Epoch 92/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8962\n",
            "Epoch 93/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8944\n",
            "Epoch 94/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8938\n",
            "Epoch 95/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8936\n",
            "Epoch 96/100\n",
            "445/445 [==============================] - 15s 33ms/step - loss: 0.8921\n",
            "Epoch 97/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8923\n",
            "Epoch 98/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8923\n",
            "Epoch 99/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8901\n",
            "Epoch 100/100\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruU-3FFXUM0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e42d6a5-5da7-49c7-ce24-4ef0942b8fb4"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imVqCCdWUOuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ug42vH1QDvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string, num_generate = 1000, temperature = 1.0):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = num_generate\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = temperature\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXCBQsgaQEZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "8a906779-197d-414a-fded-2f01aa14157b"
      },
      "source": [
        "print(generate_text(model, start_string=u\"Я люблю\", num_generate = 1000))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Я люблю злость, переродо и опять даже твои губы на то, что может побыть непроводко\n",
            "\n",
            "Жрать людям просто в голове, ведь умер 2Pac\n",
            "Плак-плак-плак,ппак!\n",
            "\n",
            "\n",
            "Это судайте, кого ных, ный лёд\n",
            "Хотя бы не познали ключок бесконечный\n",
            "Руслю у камня, ведь я не занят\n",
            "Этот этот речь записа, по ногам\n",
            "И что тебя анимпуказалось не нашли об этом\n",
            "\n",
            "Глотая жопа, пацаны, как свет видит под подошвой\n",
            "Стонет таем более толк, что не струселяем под мои глаза\n",
            "И завшли не спасут\n",
            "Чтоб умереть нужен стоит мок лучше видят громко?\n",
            "Чтоб нас помню,я до диссионим, уловишь за сделан, не умирай\n",
            "Покажи! (pow)\n",
            "Islaw\n",
            "Ты вы не первый и капкую и (рау-еф.)\n",
            "Я клачевавная вся музыка — ксовать счетах\n",
            "Я все еще увидеть конец циплер или яослалы\n",
            "Твой стафф катрицию манек. Переперепериальные друли как кровавых сердцах\n",
            "\n",
            "Шток держу в перехи, как Хавик\n",
            "Пока (брр-а)\n",
            "Вот, брошенных кровати\n",
            "Канавтишься я когда-то жёг, я когда-то мог\n",
            "На уши постмодерна\n",
            "Турская\n",
            "Пошёл на хуй посселан\n",
            "Заслучаешься по гулям\n",
            "И я бело всю нейт бетых\n",
            "Все с утра...\n",
            "\n",
            "Мое уши мне\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0YXH4-SpvDQ",
        "colab_type": "text"
      },
      "source": [
        "**Comment on RNN**\n",
        "\n",
        "Well, this piece of lyrics at least does not directly cite any real song. So it is absolutely made up song. Main points about RNN:\n",
        "1.   It is able to make new lines by itself\n",
        "2.   It is able to generate word out of just a sequence of characters (fantastic)\n",
        "3. Sometimes it generates nonexistent words :(\n",
        "4. It needs more epochs of training, more layers in model, probably more training data, et."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebMz0_Yxspzw",
        "colab_type": "text"
      },
      "source": [
        "Actually, the parameter, that is responsible for randomness in temperature. It is 1 by default, but lowering it, you can get less nonexistent words,  but more citations from songs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-0hXx_UsLTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "4a902427-24ae-41e8-cef6-19c55ec3ce35"
      },
      "source": [
        "print(generate_text(model, start_string=u\"Он\", num_generate = 1000, temperature = 0.65))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Они сходят за реклам\n",
            "В мирове если рвфоле\n",
            "Расправлю своих ветер разгонит в краску?\n",
            "Вы, гра-ладим не раскрыл и «мелок», you a the case\n",
            "Не проходит на мой хуй строги?\n",
            "Вы самых не простить и сдавай на букевольку й пусто\n",
            "Я сижу в темноте\n",
            "И она не хуже в кармане есть этих строго похуй молитвы\n",
            "Это правда\n",
            "Если я убираю рассветь успел тебе против того что-то пидорас\n",
            "Вот, б ты, красиво, без негосята беспредела вроде бы вы свили не снято нет Адрихаза — как в прошлом горядском молчами, что изменилось?\n",
            "На борцом длянов — и я просто скучаешь\n",
            "Брать воздух, как моя семья\n",
            "Я хотел сказать, что в час миллионов Гуш\n",
            "Понял то, что делал ты, стёкло очень окна, я придёт будет из колоса\n",
            "Сегодня выйдут и потрихаю в своей заесчастней!\n",
            "\n",
            "За совестных делах, она не кто только этого не хватало представляю крый уже о в храмоще с нами под Чемоден, она не нужна\n",
            "Ха-а-ха, где тебя нет, где тебя нет\n",
            "Ты ползёшь ниже плиндеребения\n",
            "И я только всё, что было, не то ей в красках\n",
            "Люди — кемная параша. Рок'н'ролл — это кал!\n",
            "\n",
            "Право\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOYngXFYtS4k",
        "colab_type": "text"
      },
      "source": [
        "And finally I will share a masterpiece, created by bigram model, trained only on Oxxxymiron lyrics (unfortunately, I didn't save the code for that):\n",
        "\n",
        "\n",
        "\n",
        "*Всегда видят лишь негатив, положив на весы*\n",
        "\n",
        "*Коллеги твердят:``может хомяка положите туда*\n",
        "\n",
        "*Abab — рифмовка никуда, ерунда!*\n",
        "\n",
        "*Бра*\n",
        "\n",
        "*Школу! сколько было всего, что я хочу сказать*\n",
        "\n",
        "*И каждый вес мутит, а мой менталитет*\n",
        "\n",
        "*Бит и бас, это наш год! до тебя*\n",
        "\n",
        "*Как раньше: лёд всё тоньше*"
      ]
    }
  ]
}