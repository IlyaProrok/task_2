{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy_of_Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlyaProrok/task_2/blob/master/task_2_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D23shHki5_KR",
        "outputId": "8a216561-b1a4-485f-ec2a-652decaa6e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "!pip install lyricsgenius\n",
        "!pip install -U pip\n",
        "!pip install -U dill\n",
        "!pip install nltk==3.5b1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lyricsgenius\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/47/5aba67735bf3b7f2b1f4c1e5d1f9892050847e27e7fafdec14fc72d41bc1/lyricsgenius-1.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (2.21.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (1.24.3)\n",
            "Installing collected packages: beautifulsoup4, lyricsgenius\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed beautifulsoup4-4.6.0 lyricsgenius-1.8.2\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.0.2\n",
            "Requirement already up-to-date: dill in /usr/local/lib/python3.6/dist-packages (0.3.1.1)\n",
            "Collecting nltk==3.5b1\n",
            "  Downloading nltk-3.5b1.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (0.14.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (4.38.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5b1-py3-none-any.whl size=1434694 sha256=3a62905cd70aa8b9bcbc42ecbe64cb97531227d42fa4a3b814e505d0548b1a01\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/86/25/c46dd9a7eced213ff414cc8266b44bb26e61f3f787d36d8dfc\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.5b1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2huXugIXfZNd",
        "outputId": "343be58a-9289-4559-d760-030cbbe3d0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import lyricsgenius\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "from nltk import tokenize\n",
        "from nltk.tokenize import LineTokenizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm import Laplace\n",
        "from nltk.lm import KneserNeyInterpolated\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "import random\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.lm import Vocabulary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cULWJubXfe2e",
        "colab": {}
      },
      "source": [
        "genius = lyricsgenius.Genius(\"iihP9u6cVKE79Xtu99OH6rVZlMUzIMeOvIVs8BDQNDeVmZhXJXEaI28E6QOc4BdB\")\n",
        "genius.remove_section_headers = True\n",
        "genius.skip_non_songs = False \n",
        "genius.excluded_terms = [\"(Remix)\", \"(Live)\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SEuo5G2ZA3mO",
        "colab": {}
      },
      "source": [
        "Oxxxymiron = genius.search_artist(\"Oxxxymiron\", sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOblUhlprVW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SlavaKPSS = genius.search_artist(\"Слава КПСС\", sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAWk0mGjzowZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NoizeMC = genius.search_artist(\"Noize MC\", sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAflIU14738d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FACE = genius.search_artist(\"FACE\", sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "12TBjtrlcm9z",
        "outputId": "3d485a2b-cbc6-488e-c181-128a929bc150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# saving the lyrics of all songs of Oxxxymiron\n",
        "Oxxxymiron.save_lyrics(extension='txt')\n",
        "SlavaKPSS.save_lyrics(extension='txt')\n",
        "NoizeMC.save_lyrics(extension='txt')\n",
        "FACE.save_lyrics(extension='txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote `Lyrics_Oxxxymiron.txt`\n",
            "Wrote `Lyrics_СлаваКПССSlavaKPSS.txt`\n",
            "Wrote `Lyrics_NoizeMC.txt`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8OS5Uhfjc-aH",
        "colab": {}
      },
      "source": [
        "Oxy_lyrics = open(\"Lyrics_Oxxxymiron.txt\",\"r\")\n",
        "Slava_lyrics = open(\"Lyrics_СлаваКПССSlavaKPSS.txt\",\"r\")\n",
        "Noize_lyrics = open(\"Lyrics_NoizeMC.txt\",\"r\")\n",
        "# FACE_lyrics = open(\"Lyrics_FACE.txt\",\"r\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIUL2shyxM0W",
        "colab": {}
      },
      "source": [
        "# tokenizing the lyrics, probably the tokenization is raw and there is anything I missed?\n",
        "Oxy_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in Oxy_lyrics]\n",
        "Slava_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in Slava_lyrics]\n",
        "Noize_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in Noize_lyrics]\n",
        "FACE_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  # for sent in FACE_lyrics]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBKgnIp0-qJM",
        "colab_type": "code",
        "outputId": "81085b5f-39ed-400e-c759-a8f352ef2545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(Oxy_tokenized),len(Slava_tokenized),len(Noize_tokenized),len(FACE_tokenized))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5280 13440 16633 5487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BILLTGug9WYS",
        "colab_type": "code",
        "outputId": "199409bd-22ee-4d0a-e9cc-ec9f7dca070d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "all_lyrics = []\n",
        "all_lyrics.extend(Oxy_tokenized)\n",
        "all_lyrics.extend(Slava_tokenized)\n",
        "all_lyrics.extend(Noize_tokenized)\n",
        "all_lyrics.extend(FACE_tokenized)\n",
        "print(len(all_lyrics))\n",
        "print(len(Oxy_tokenized)+len(Slava_tokenized)+len(Noize_tokenized)+len(FACE_tokenized))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30164\n",
            "30164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lg7JIPQ_5xME",
        "colab": {}
      },
      "source": [
        "# Firstly, I was thinking, that adding \\n symbol is a good idea to let the model know, where to start the next line,\n",
        "# but then i neglected the idea\n",
        "# for strokes in tokenized_text:\n",
        "#   strokes.append('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZsBp0KUWdKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def a function to generate rap text given a model\n",
        "def rap_gen(model, num_lines = 20, num_words_in_line = 20, random_seed = 0):\n",
        "  \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "  detokenize = TreebankWordDetokenizer().detokenize\n",
        "  for i in range(num_lines):\n",
        "    content = []\n",
        "    for token in model.generate(num_words_in_line, random_seed=random_seed+i):\n",
        "      if token == '<s>':\n",
        "        continue\n",
        "      if token == '</s>':\n",
        "        break\n",
        "      content.append(token)\n",
        "    content = detokenize(content)\n",
        "    if bool(content):\n",
        "      i = 0\n",
        "      while not content[i].isalpha():\n",
        "          i += 1\n",
        "          if i > len(content)-1:\n",
        "            break\n",
        "      print(content[i:].capitalize())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXFpQ9hWSP1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(all_lyrics, test_size=0.3, random_state=11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3sANXcx_brs",
        "colab_type": "text"
      },
      "source": [
        "Unigram models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HwYorYV_dpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_MLE = MLE(1)\n",
        "train_data1_1, padded_sents1_1 = padded_everygram_pipeline(1, train)\n",
        "model1_MLE.fit(train_data1_1, padded_sents1_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQK--1DO_bF1",
        "colab_type": "code",
        "outputId": "1fcb0074-d7a0-4bd7-d834-08f51c5090e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "rap_gen(model1_MLE, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Коли оркестром отстой?! ж во сначала по не\n",
            "Вверх плавниками пират твоего а быть a бы проблем 1\n",
            "Поездку он что владимир вани проблема основанная высокой писал\n",
            "Этом! проезжали it я\"туссин петушина телами “\n",
            "Дядька корни и к и орфея ваще ночью! вынул\n",
            "Меня слушая это всем ртом пойду от ,) за\n",
            "От дверью барабаны кто курт копов как весь важных\n",
            "Пенсии свободу меня лягу зале — всем and ведь ведь\n",
            "Услышав планеты рублём упакован ведут ну упрямо тот надеюсь start\n",
            "Oh по ночью конч брендом сейчас смена мажет лоли в\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbkc7Kam_v-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_Lapl = Laplace(1)\n",
        "train_data1_2, padded_sents1_2 = padded_everygram_pipeline(1, train)\n",
        "model1_Lapl.fit(train_data1_2, padded_sents1_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5dRT2szAC9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rap_gen(model1_Lapl, num_lines=10,num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sNVOUUNKClt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_KNI = KneserNeyInterpolated(1)\n",
        "train_data1_3, padded_sents1_3 = padded_everygram_pipeline(1, train)\n",
        "model1_KNI.fit(train_data1_3, padded_sents1_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU4YaaKwKVN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rap_gen(model1_KNI, num_lines=10,num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lhEfp-7EXOx",
        "colab_type": "text"
      },
      "source": [
        "Everygram models (until bigram)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udr5R9fSLO3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2_MLE = MLE(2)\n",
        "train_data2_1, padded_sents2_1 = padded_everygram_pipeline(2, train)\n",
        "model2_MLE.fit(train_data2_1, padded_sents2_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Fu22xJvxt05",
        "outputId": "14caaf13-2700-4d82-bff2-f8b233bd24cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rap_gen(model2_MLE, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Да вот так, bang, зато построишь дом\n",
            "По радио и гимном встречу похмельное утро он был\n",
            "Ипотечными котлами\n",
            "Эти 3 ночи, я, что с того чтобы\n",
            "\n",
            "За такую хуйню: ваш трэк, будто\n",
            "Наш сигнал не ныл\n",
            "Тупорылый текст писал эсэмэски\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6iobw1Qrxv4T",
        "colab": {}
      },
      "source": [
        "model2_Lapl = Laplace(2)\n",
        "train_data2_2, padded_sents2_2 = padded_everygram_pipeline(2, train)\n",
        "model2_Lapl.fit(train_data2_2, padded_sents2_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKySLgRKLBoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rap_gen(model2_Lapl, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJRYwAhYdTLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2_KNI = KneserNeyInterpolated(2)\n",
        "train_data2_3, padded_sents2_3 = padded_everygram_pipeline(2, train)\n",
        "model2_KNI.fit(train_data2_3, padded_sents2_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiOAqhZFLEBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rap_gen(model2_KNI, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VGqVckcLHp7",
        "colab_type": "text"
      },
      "source": [
        "Everygram models (until trigram)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz_OfUbhJQDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3_MLE = MLE(3)\n",
        "train_data3_1, padded_sents3_1 = padded_everygram_pipeline(3, train)\n",
        "model3_MLE.fit(train_data3_1, padded_sents3_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VleANnbaLgVK",
        "colab_type": "code",
        "outputId": "ddfb6caa-1eab-40b4-dd73-b9498bd748d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "rap_gen(model3_MLE, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ока » , 13-го — в шоколаде весь рот\n",
            "Чём, кроме\n",
            "Или на парах . (и в интернете\n",
            "В тапки\n",
            "Куча копий нашей планеты :\n",
            "Твоё табло и мега-турбо-супер-хайп\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkL8a8gyLjci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3_Lapl = Laplace(3)\n",
        "train_data3_2, padded_sents3_2 = padded_everygram_pipeline(3, train)\n",
        "model3_Lapl.fit(train_data3_2, padded_sents3_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX8v9oA0Lwjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rap_gen(model3_Lapl, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wimJziDoLxaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3_KNI = KneserNeyInterpolated(3)\n",
        "train_data3_3, padded_sents3_3 = padded_everygram_pipeline(3, train)\n",
        "model3_KNI.fit(train_data3_3, padded_sents3_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2htw825L3ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rap_gen(model3_KNI, num_lines=10, num_words_in_line=10,random_seed = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzyk9wxriHNw",
        "colab_type": "text"
      },
      "source": [
        "The generated texts are really strange, actually (however, i'm not a rap expert, probably, this is OK :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVREtGk5iuWH",
        "colab_type": "text"
      },
      "source": [
        "Can you also give some advise on a model evaluation with perplexity. Thing I did below, unfortunately, do not give desired result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEHuvi1Ef401",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data1,_ = padded_everygram_pipeline(1, test)\n",
        "test_data2,_ = padded_everygram_pipeline(2, test)\n",
        "test_data3,_ = padded_everygram_pipeline(3, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0E6oR-pWLdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen1 = []\n",
        "test_gen2 = []\n",
        "test_gen3 = []\n",
        "for line in test_data1:\n",
        "  test_gen1.extend(line)\n",
        "for line in test_data2:\n",
        "  test_gen2.extend(line)\n",
        "for line in test_data3:\n",
        "  test_gen3.extend(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1OCTA6cgFFN",
        "colab_type": "code",
        "outputId": "74577ab2-cab9-4d9b-8414-7b626137cc44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for unigram MLE model is: {}'.format(model1_MLE.perplexity(test_gen1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for unigram MLE model is: inf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak-VJeaBWj5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Perplexity for unigram Laplace model is: {}'.format(model1_Lapl.perplexity(test_gen1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6M8OtwGWtuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Perplexity for unigram KneserNeyInterpolated model is: {}'.format(model1_KNI.perplexity(test_gen1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9C-dc1gW2lx",
        "colab_type": "code",
        "outputId": "6ea7a429-49a3-42b8-ca4f-76bf039a12fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for bigram MLE model is: {}'.format(model2_MLE.perplexity(test_gen2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for bigram MLE model is: inf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ads7J__gW5sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Perplexity for bigram Laplace model is: {}'.format(model2_Lapl.perplexity(test_gen2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bLeY-uBW9it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Perplexity for bigram KneserNeyInterpolated model is: {}'.format(model2_KNI.perplexity(test_gen2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M7lyutpXAw7",
        "colab_type": "code",
        "outputId": "fae169dd-16cc-470f-e78b-178b48d93dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Perplexity for trigram MLE model is: {}'.format(model3_MLE.perplexity(test_gen3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity for trigram MLE model is: inf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwDCH3RMXDzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Perplexity for trigram Laplace model is: {}'.format(model3_Lapl.perplexity(test_gen3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13n0e6j0XGrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Perplexity for trigram KneserNeyInterpolated model is: {}'.format(model3_KNI.perplexity(test_gen3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsbgNvFnETru",
        "colab_type": "text"
      },
      "source": [
        "Everygram models (until trigram)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbfb_kmhESsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bigram_padded = []\n",
        "for i in range(len(train)):\n",
        "  stroke = list(pad_sequence(train[i],\n",
        "                  pad_left=True, left_pad_symbol=\"<s>\",\n",
        "                  pad_right=True, right_pad_symbol=\"</s>\",\n",
        "                  n=2))\n",
        "  train_bigram_padded.append(stroke)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syIOkKvbFRI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bigram_padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKj06ydWFm8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bigram = []\n",
        "train_bigram = [list(ngrams(train_bigram_padded[i], n=2)) for i in range(len(train_bigram_padded))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHdYRegTQrSx",
        "colab_type": "code",
        "outputId": "d5197722-0df0-4749-9cdf-505b553edcbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "iterat = iter(train_bigram)\n",
        "iterat"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<list_iterator at 0x7feb99300a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAMgayDCF2K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_bigram = []\n",
        "flat_bigram = list(flatten(train_bigram_padded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oCPsor80NOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_bigram = Vocabulary(flat_bigram,unk_cutoff=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjSg_JOcQTvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = MLE(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2BrmvscQWfC",
        "colab_type": "code",
        "outputId": "3bf56d78-cf22-43bc-98dd-8071514f291b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(model3.vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfE1y2n5QjcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.fit(iterat, vocab_bigram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjiR4wYURosH",
        "colab_type": "code",
        "outputId": "b3ef916c-baf6-43a6-fd8c-daf60d49e7aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(model3.vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRWmxo7Oxl57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-0GGhSWRsXo",
        "colab_type": "code",
        "outputId": "21a1a6f3-b92e-42ca-8deb-54b356344a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "rap_gen(model3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-b55048b761b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrap_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-8285fe49cdae>\u001b[0m in \u001b[0;36mrap_gen\u001b[0;34m(model, num_lines, num_words_in_line, random_seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words_in_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'<s>'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, num_words, text_seed, random_seed)\u001b[0m\n\u001b[1;32m    227\u001b[0m                     \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                     \u001b[0mtext_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_seed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                     \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m                 )\n\u001b[1;32m    231\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, num_words, text_seed, random_seed)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mrandom_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# We build up text one word at a time using the preceding context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36m_weighted_choice\u001b[0;34m(population, weights, random_generator)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't choose from empty population\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The number of weights does not match the population\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't choose from empty population"
          ]
        }
      ]
    }
  ]
}